# -*- coding: utf-8 -*-
"""Encrypter Password.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1epQO5F5tB7kKC71Irnh9idH4hrENPc6L

**AGARRA UN .TXT DE MUCHAS CONTRASEÑAS Y LAS ENCRIPTA**
"""

!pip install bcrypt

from google.colab import files
import bcrypt

# Función para generar el hash bcrypt de una contraseña
def generate_bcrypt_hash(password):
    salt = bcrypt.gensalt()
    hashed_password = bcrypt.hashpw(password.encode('utf-8'), salt)
    return hashed_password.decode('utf-8')

# Subir el archivo de contraseñas desde tu PC
print("Selecciona el archivo de contraseñas:")
uploaded = files.upload()

# Obtener el nombre del archivo cargado
nombre_archivo_contras = list(uploaded.keys())[0]

# Leer el archivo de contraseñas
contras = []
with open(nombre_archivo_contras, "r") as file:
    for line in file:
        contras.append(line.strip())

# Encriptar las contraseñas
contras_encriptadas = [generate_bcrypt_hash(password) for password in contras]

# Guardar los hashes en un archivo local
ruta_archivo_hashes = '/content/hashes.txt'
with open(ruta_archivo_hashes, "w") as file:
    for hash in contras_encriptadas:
        file.write(hash + "\n")

# Descargar automáticamente el archivo
files.download(ruta_archivo_hashes)

"""**COMPARA UNA CONTRASEÑA ENCRIPTADA CON UNA NORMAL Y VERIFICA SI ES VÁLIDA O NO**"""

!pip install bcrypt

import bcrypt

# Función para verificar si la clave coincide con su versión encriptada
def verificar_clave(clave_sin_encriptar, clave_encriptada):
    return bcrypt.checkpw(clave_sin_encriptar.encode('utf-8'), clave_encriptada.encode('utf-8'))

# Ingresar la clave encriptada y la clave sin encriptar
clave_encriptada = input("Ingresa la clave encriptada: ")
clave_sin_encriptar = input("Ingresa la clave sin encriptar: ")

# Verificar si las claves coinciden
coinciden = verificar_clave(clave_sin_encriptar, clave_encriptada)

# Mostrar el resultado
if coinciden:
    print("Las claves coinciden.")
else:
    print("Las claves no coinciden.")

"""**ENCRIPTA UNA CONTRASEÑA**"""

!pip install bcrypt

import bcrypt

# Función para encriptar una contraseña con bcrypt
def encriptar_contrasena(contrasena):
    salt = bcrypt.gensalt()
    hash_bcrypt = bcrypt.hashpw(contrasena.encode(), salt)
    return hash_bcrypt.decode()

# Contraseña a encriptar
contrasena = "Selecu123"

# Encriptar la contraseña
hash_encriptado = encriptar_contrasena(contrasena)

# Imprimir el hash encriptado
print("Contraseña encriptada:", hash_encriptado)

!pip install rarfile

import os
import shutil
import pandas as pd
from google.colab import files

# Cargar el archivo Excel
archivo_excel = pd.ExcelFile('claves.xlsx')

# Obtener nombres de las hojas
nombres_hojas = archivo_excel.sheet_names

# Crear un directorio temporal para almacenar los archivos intermedios
temp_dir = 'temp_dir'
os.makedirs(temp_dir, exist_ok=True)

# Iterar sobre las hojas
for hoja_nombre in nombres_hojas:
    # Leer datos de la hoja actual
    df = archivo_excel.parse(hoja_nombre)

    # Obtener valores únicos de las columnas relevantes
    centros_experiencia = df['Centro de Experiencia'].unique()

    # Iterar sobre los centros de experiencia
    for centro in centros_experiencia:
        centro_df = df[df['Centro de Experiencia'] == centro]

        # Obtener grupos únicos para el centro actual
        grupos = centro_df['Grupo'].unique()

        # Iterar sobre los grupos
        for grupo in grupos:
            grupo_df = centro_df[centro_df['Grupo'] == grupo]

            # Crear un nombre de archivo
            nombre_archivo = f'{centro}_{grupo}.xlsx'

            # Guardar el DataFrame en un nuevo archivo Excel
            grupo_df.to_excel(os.path.join(temp_dir, nombre_archivo), index=False)

# Crear un archivo ZIP en lugar de RAR
shutil.make_archive('archivos_comprimidosdddd', 'zip', temp_dir)

# Descargar automáticamente el archivo ZIP
files.download('archivos_comprimidosdddd.zip')

from google.colab import files

# Sube los archivos de texto
uploaded = files.upload()

# Verifica los nombres de los archivos cargados
file_names = list(uploaded.keys())

# Verifica si se cargaron exactamente dos archivos
if len(file_names) != 2:
    print("Por favor, carga exactamente dos archivos de texto.")
else:
    # Lee los números de los archivos
    with open(file_names[0], 'r') as file1, open(file_names[1], 'r') as file2:
        numbers1 = set(map(int, file1.read().split()))
        numbers2 = set(map(int, file2.read().split()))

    # Encuentra los números que están en el primer archivo pero no en el segundo
    difference = numbers1 - numbers2

    # Muestra los resultados
    print("Números en el primer archivo pero no en el segundo:")
    print(sorted(difference))

import pandas as pd
from google.colab import files

def procesar_excel(archivo_entrada, archivo_salida):
    # Cargar el archivo Excel
    df = pd.read_excel(archivo_entrada)

    # Iterar sobre las filas y actualizar el resultado
    for index, fila in df.iterrows():
        grupo_estudiante = fila['Grupo 2024 Estudiante']
        codigo_grupo = fila['Codigo Grupo 2024']

        # Buscar coincidencia en Codigo Grupo 2024
        resultado = df.loc[df['Codigo Grupo 2024'] == grupo_estudiante, 'ID Grupo'].values

        # Actualizar el valor en la columna 'Resultado'
        df.at[index, 'Resultado'] = resultado[0] if len(resultado) > 0 else None

    # Guardar el DataFrame actualizado en un nuevo archivo Excel
    df.to_excel(archivo_salida, index=False)

# Cargar el archivo desde tu PC
print("Carga el archivo de entrada:")
archivo_entrada = files.upload()

# Obtener el nombre del archivo cargado
nombre_archivo_entrada = list(archivo_entrada.keys())[0]

# Definir el nombre del archivo de salida
nombre_archivo_salida = 'salida.xlsx'

# Llama a la función para procesar el archivo Excel
procesar_excel(nombre_archivo_entrada, nombre_archivo_salida)

# Descargar el archivo procesado
files.download(nombre_archivo_salida)

import pandas as pd

def buscar_documentos_repetidos(beta_file, original_file, output_file):
    # Cargar los archivos de Excel en DataFrames
    beta_df = pd.read_excel(beta_file)
    original_df = pd.read_excel(original_file)

    # Obtener los documentos que se repiten en ambos archivos
    documentos_repetidos = pd.merge(beta_df['Documento'], original_df['Documento'], on='Documento', how='inner')

    # Filtrar las contraseñas correspondientes a los documentos repetidos
    contrasenas = original_df[original_df['Documento'].isin(documentos_repetidos['Documento'])]['Contra']

    # Guardar las contraseñas en un archivo de texto
    with open(output_file, 'w') as file:
        for contrasena in contrasenas:
            file.write(str(contrasena) + '\n')

    print(f"Se han guardado las contraseñas en el archivo: {output_file}")


# Ruta de los archivos de Excel
beta_file = '/content/beta.xlsx'
original_file = '/content/original.xlsx'

# Nombre y ruta del archivo de texto de salida
output_file = '/content/contrasenas.txt'

# Llamar a la función para buscar los documentos repetidos y extraer las contraseñas
buscar_documentos_repetidos(beta_file, original_file, output_file)

import pandas as pd

# Cargar los datos de los archivos de Excel
df_cosmo = pd.read_excel('Bases de datos Cosmo 2023.xlsx', sheet_name='I. E Bucarelly ')
df_faltantes = pd.read_excel('Existentes DB Faltantes Excel.xlsx', sheet_name='Hoja1')

# Filtrar los registros en Existentes DB Faltantes Excel con ID entre 2212  y 2275
filtro_id = df_faltantes['ID'].between(2212, 2275)
registros_faltantes = df_faltantes.loc[filtro_id, 'Nombre']

# Buscar los registros en Bases de datos Cosmo 2023 que coinciden con los nombres
filtro_nombres = df_cosmo['Nombres y Apellidos Estudiante'].isin(registros_faltantes)
registros_cosmo = df_cosmo.loc[filtro_nombres, ['Nombres y Apellidos Estudiante', 'grupo', 'N° de Documento']]

# Combinar los datos en Existentes DB Faltantes Excel con los datos encontrados en Bases de datos Cosmo 2023
df_faltantes = pd.merge(df_faltantes, registros_cosmo, left_on='Nombre', right_on='Nombres y Apellidos Estudiante', how='left')
df_faltantes.drop(columns=['Nombres y Apellidos Estudiante'], inplace=True)

# Guardar el resultado en un nuevo archivo de Excel
df_faltantes.to_excel('Existentes DB Faltantes Actualizado.xlsx', index=False)

import pandas as pd

# Leer los datos de los archivos Excel
df_beta = pd.read_excel('beta.xlsx')
xls_cosmo = pd.read_excel('prueba.xlsx', sheet_name=None)

# Crear una lista para almacenar los resultados
results = []

# Iterar sobre todas las hojas del archivo
for sheet_name, df_cosmo in xls_cosmo.items():
    # Realizar la operación de búsqueda y seleccionar las columnas deseadas
    df_result = df_beta.merge(df_cosmo[['Identificación', 'Nombre sede', 'Grado', 'Grupo']], on='Identificación')
    # Agregar los resultados a la lista
    results.append(df_result)

# Combinar todos los resultados en un único DataFrame
df_combined = pd.concat(results)

# Guardar los resultados en un archivo Excel
with pd.ExcelWriter('resultados.xlsx') as writer:
    df_combined.to_excel(writer, index=False, sheet_name='Resultados')

print("Se han guardado los resultados en el archivo resultados.xlsx.")

"""**COMPARA DOS ARCHIVOS, UNO CON CONTRASEÑAS NORMALES Y OTRO CON CONTRASEÑAS ENCRIPTADAS. LAS COINCIDENCIAS LAS EXPORTA COMO "SI" Y LAS QUE NO COMO "NO". AMBOS DEBEN TENER EL MISMO ORDEN Y LA MISMA CANTIDAD DE CONTRASEÑAS**"""

!pip install bcrypt

import bcrypt

# Función para verificar si una contraseña coincide con el hash bcrypt
def verificar_contrasena(contrasena, hash_bcrypt):
    return bcrypt.checkpw(contrasena.encode(), hash_bcrypt)

# Ruta de los archivos de contraseñas
archivo_users = '/content/users.txt'
archivo_pass = '/content/pass.txt'

# Leer los datos de los archivos de contraseñas
with open(archivo_users, 'r') as file_users, open(archivo_pass, 'r') as file_pass:
    # Leer las contraseñas sin encriptar del archivo users.txt
    contrasenas_users = [line.strip() for line in file_users.readlines()]

    # Leer los hashes bcrypt del archivo pass.txt
    hashes_bcrypt = [line.strip() for line in file_pass.readlines()]

# Crear una lista para almacenar los resultados
resultados = []

# Verificar si las contraseñas coinciden y son correctas
for contrasena, hash_bcrypt in zip(contrasenas_users, hashes_bcrypt):
    # Verificar si la contraseña coincide con el hash bcrypt
    if verificar_contrasena(contrasena, hash_bcrypt.encode()):
        resultados.append('SI')
    else:
        resultados.append('NO')

# Escribir los resultados en el archivo resultados.txt
with open('/content/resultadosfull.txt', 'w') as file_resultados:
    for resultado in resultados:
        file_resultados.write(resultado + '\n')

print("Se han generado los resultados en el archivo resultadosfull.txt.")

import pandas as pd
from google.colab import files

# Cargar el archivo Excel
uploaded = files.upload()

# Leer el archivo Excel
df_cosmo = pd.read_excel('Comparativo.xlsx', sheet_name='DB Cosmo')
df_selecu = pd.read_excel('Comparativo.xlsx', sheet_name='DB Selecu')

# Filtrar las identificaciones comunes
identificaciones_comunes = df_cosmo[df_cosmo['Identificación'].isin(df_selecu['Identificación'])]['Identificación']

# Guardar las identificaciones en un archivo de texto
identificaciones_comunes.to_csv('identificaciones_comunes.txt', index=False, header=False)

# Descargar el archivo de texto
files.download('identificaciones_comunes.txt')

import pandas as pd
from google.colab import files

# Cargar el archivo Excel y el archivo de identificaciones comunes
uploaded = files.upload()

# Leer el archivo Excel y el archivo de identificaciones comunes
df_comparativo = pd.read_excel('Comparativo.xlsx', sheet_name='DB Selecu')
df_identificaciones = pd.read_csv('identificaciones_comunes.txt', header=None, squeeze=True)

# Filtrar los registros a eliminar
df_eliminar = df_comparativo[df_comparativo['Identificación'].isin(df_identificaciones)]

# Eliminar los registros del DataFrame
df_comparativo = df_comparativo.drop(df_eliminar.index)

# Guardar el DataFrame actualizado en un nuevo archivo Excel
df_comparativo.to_excel('Comparativo_actualizado.xlsx', index=False)

# Descargar el archivo Excel actualizado
files.download('Comparativo_actualizado.xlsx')

import pandas as pd
from google.colab import files

# Solicitar y cargar el archivo de la antigua hoja2
print("Selecciona el archivo de la antigua Hoja2:")
uploaded_hoja2 = files.upload()
excel_hoja2_filename = next(iter(uploaded_hoja2))

# Solicitar y cargar el archivo de la antigua hoja1
print("Selecciona el archivo de la antigua Hoja1:")
uploaded_hoja1 = files.upload()
excel_hoja1_filename = next(iter(uploaded_hoja1))

# Leer los archivos Excel y obtener los datos
df_hoja2 = pd.read_excel(excel_hoja2_filename)
df_hoja1 = pd.read_excel(excel_hoja1_filename)

# Obtener las identificaciones de la antigua Hoja1
identificaciones_hoja1 = set(df_hoja1['Identificación'])

# Filtrar los registros de la antigua Hoja2 que coinciden con la antigua Hoja1
df_hoja2 = df_hoja2[df_hoja2['Identificación'].isin(identificaciones_hoja1)]

# Crear un nuevo archivo Excel con las hojas actualizadas
output_filename = 'Excel_modificado.xlsx'
with pd.ExcelWriter(output_filename) as writer:
    df_hoja2.to_excel(writer, sheet_name='Hoja2', index=False)
    df_hoja1.to_excel(writer, sheet_name='Hoja1', index=False)

# Descargar el archivo Excel modificado
files.download(output_filename)

!pip install bcrypt

import bcrypt

def comparar_claves_encriptadas(clave_original, clave_encriptada1, clave_encriptada2):
    return bcrypt.checkpw(clave_original.encode('utf-8'), clave_encriptada1.encode('utf-8')) and bcrypt.checkpw(clave_original.encode('utf-8'), clave_encriptada2.encode('utf-8'))

# Ingresar la clave original y las claves encriptadas por teclado
clave_original = input("Ingresa la clave original: ")
clave_encriptada1 = input("Ingresa la primera clave encriptada: ")
clave_encriptada2 = input("Ingresa la segunda clave encriptada: ")

# Verificar si las claves encriptadas coinciden con la clave original
if comparar_claves_encriptadas(clave_original, clave_encriptada1, clave_encriptada2):
    print("Ambas claves encriptadas coinciden con la clave original.")
else:
    print("Al menos una de las claves encriptadas no coincide con la clave original.")

# Instalar las bibliotecas necesarias
!pip install pydub

# Importar las bibliotecas necesarias
from pydub import AudioSegment

# Cargar los archivos de audio
voice_audio_path = "voz ronaldo.wav" # Reemplaza con el nombre de tu archivo de voz
music_audio_path = "musica base.mp3" # Reemplaza con el nombre de tu archivo de pista musical

# Cargar los archivos de audio en objetos AudioSegment
voice_audio = AudioSegment.from_file(voice_audio_path)
music_audio = AudioSegment.from_file(music_audio_path)

# Asegurarse de que ambos audios tengan la misma frecuencia de muestreo (si no lo tienen)
if voice_audio.frame_rate != music_audio.frame_rate:
    voice_audio = voice_audio.set_frame_rate(music_audio.frame_rate)

# Combinar los audios superponiendo la voz sobre la pista musical
combined_audio = music_audio.overlay(voice_audio)

# Guardar el audio combinado en un archivo
output_file_path = "combinado.mp3" # Puedes cambiar el nombre del archivo de salida si lo deseas
combined_audio.export(output_file_path, format="mp3")

# Descargar el archivo combinado
from google.colab import files
files.download(output_file_path)

"""**SCRIPT PARA CORREGIR EL BUG DE 2.1.1.0**"""

import pandas as pd
import mysql.connector

# Conecta a la base de datos MySQL
db = mysql.connector.connect(
    host='rds-selecu.cdwgxarbeipl.us-east-1.rds.amazonaws.com',
    user='admin',
    password='UuVHfFf28nSuH2Vu',
    database='prod-selecu'
)
cursor = db.cursor()

# Consulta SQL para seleccionar los datos que cumplen con tus condiciones
query = """
SELECT i.id, i.userId, i.checkpointAssociated
FROM interaction i
INNER JOIN `user` u ON u.id = i.userId
WHERE u.roles = 'Student' AND i.checkpointAssociated LIKE '%.0'
ORDER BY i.userId, i.updated_at
"""

# Ejecuta la consulta SQL
cursor.execute(query)

# Obtiene los resultados en una lista de tuplas
results = cursor.fetchall()

# Reinicia el contador para cada usuario
current_user_id = None
row_number = 0

# Lista para almacenar las filas actualizadas
updated_rows = []

# Función para actualizar el checkpointAssociated
def update_checkpoint(row, current_user_id, row_number):
    if current_user_id != row[1]:
        current_user_id = row[1]
        row_number = 1
    else:
        row_number += 1
    updated_row = (f'2.1.1.{row_number}', row[0])  # (Nuevo checkpoint, id)
    return updated_row, current_user_id, row_number

# Actualiza las filas y las agrega a la lista de filas actualizadas
for row in results:
    updated_row, current_user_id, row_number = update_checkpoint(row, current_user_id, row_number)
    updated_rows.append(updated_row)

# Actualiza la columna checkpointAssociated en la tabla principal
update_query = "UPDATE interaction i SET i.checkpointAssociated = %s WHERE i.id = %s"
cursor.executemany(update_query, updated_rows)
db.commit()

# Cierra la conexión a la base de datos
db.close()

import pandas as pd
import re

# Función para extraer los valores de cada registro
def extract_values(line):
    values = re.findall(r"'(.*?)'", line)
    return values

# Leer el archivo .txt y extraer los valores de cada registro
with open('archivo.txt', 'r') as file:
    lines = file.readlines()

data = [extract_values(line) for line in lines]

# Crear un DataFrame con los datos y dividir en 4 columnas
df = pd.DataFrame(data, columns=['Columna1', 'Columna2', 'Columna3', 'Columna4'])

# Guardar el DataFrame en un archivo Excel
df.to_excel('output.xlsx', index=False)

from google.colab import files

# Pide al usuario que cargue el archivo
uploaded = files.upload()

# Obtiene el nombre del archivo cargado
archivo_entrada = list(uploaded.keys())[0]

# Función para procesar los nombres y números de identificación
def procesar_registros(registros):
    resultados = []
    for registro in registros:
        partes = registro.split('\t')
        if len(partes) == 2:
            num_documento, nombre_completo = partes
            primer_nombre = nombre_completo.split()[0].lower()
            dos_primeros_digitos = num_documento[:2]
            resultado = f'{primer_nombre}{dos_primeros_digitos}'
            resultados.append(resultado)
    return resultados

# Leer el archivo de entrada y procesar los registros
with open(archivo_entrada, 'r') as file:
    registros = file.readlines()

nuevos_registros = procesar_registros(registros)

# Escribir los resultados en un nuevo archivo de texto
archivo_salida = 'resultados.txt'
with open(archivo_salida, 'w') as file:
    for registro in nuevos_registros:
        file.write(registro + '\n')

print('Proceso completado. Los registros procesados han sido guardados en el archivo de salida "resultados.txt".')

import pandas as pd

# Cargar el archivo de Excel
archivo_excel = 'tablaDatosPruebaEntrada.xlsx'  # Reemplaza con el nombre de tu archivo
df = pd.read_excel(archivo_excel)

# Imprimir las columnas disponibles
print("Columnas disponibles:", df.columns)

# Inicializar el contenido del bloc de notas
resultados_txt = ""

# Iterar sobre las filas del DataFrame
for index, row in df.iterrows():
    # Obtener el valor de la columna B y K de cada fila
    valor_b = row['Documento']
    valor_k = row['Orden grado']  # Reemplaza 'Columna_K' con el nombre real de tu columna K

    # Verificar si el valor en B es numérico
    if pd.notna(valor_b) and isinstance(valor_b, (int, float)):
        # Iterar sobre las celdas de la fila y multiplicar por 100 si es numérico
        for col, valor in row['Ciencias Naturales':'Matematicas_resolucion de problemas'].iteritems():
            if pd.notna(valor) and isinstance(valor, (int, float)):
                # Obtener el nombre de la materia desde la fila 1 (encabezados)
                materia = df.loc[0, col]
                valor_multiplicado = valor * 100
                # Adjuntar información al bloc de notas
                resultados_txt += f"{valor_b}, {materia}, {valor_multiplicado}, {valor_k}\n"

# Guardar resultados en un archivo txt
with open('resultados.txt', 'w') as f:
    f.write(resultados_txt)

print("Operación completada. Resultados guardados en 'resultados.txt'")

import pandas as pd
from openpyxl import load_workbook
from openpyxl.styles import PatternFill, Font

# Cargar el archivo con los IDs
ids_df = pd.read_excel('ids.xlsx', header=None, names=['ID'])

# Cargar los nuevos archivos
archivo1_df = pd.read_excel('MismoNombreDiffDocumento.xlsx')
archivo2_df = pd.read_excel('MismoNombreMismoDocumentoDiffInstitucion.xlsx')

# Iterar sobre los IDs y buscar coincidencias en ambos archivos
for _, id_row in ids_df.iterrows():
    id_to_search = id_row['ID']

    # Buscar coincidencias en el primer archivo
    coincidencias_archivo1 = archivo1_df[archivo1_df['ID'] == id_to_search].index.tolist()

    # Buscar coincidencias en el segundo archivo
    coincidencias_archivo2 = archivo2_df[archivo2_df['ID'] == id_to_search].index.tolist()

    # Resaltar coincidencias en el primer archivo
    for idx in coincidencias_archivo1:
        archivo1_df.at[idx, 'ID'] = f'<b>{id_to_search}</b>'

    # Resaltar coincidencias en el segundo archivo
    for idx in coincidencias_archivo2:
        archivo2_df.at[idx, 'ID'] = f'<b>{id_to_search}</b>'

# Guardar los resultados en nuevos archivos Excel
with pd.ExcelWriter('MismoNombreDiffDocumento_modificado.xlsx', engine='openpyxl') as writer:
    writer.book = load_workbook('MismoNombreDiffDocumento.xlsx')
    archivo1_df.to_excel(writer, sheet_name='Sheet1', index=False)

with pd.ExcelWriter('MismoNombreMismoDocumentoDiffInstitucion_modificado.xlsx', engine='openpyxl') as writer:
    writer.book = load_workbook('MismoNombreMismoDocumentoDiffInstitucion.xlsx')
    archivo2_df.to_excel(writer, sheet_name='Sheet1', index=False)

import pandas as pd
from openpyxl import load_workbook

# Cargar ambos archivos
archivo1_df = pd.read_excel('MismoNombreDiffDocumento.xlsx')
archivo2_df = pd.read_excel('MismoNombreMismoDocumentoDiffInstitucion.xlsx')

# Identificar los índices de los registros en archivo1 que también están en archivo2
indices_coincidentes = archivo1_df[archivo1_df['ID'].isin(archivo2_df['ID'])].index

# Eliminar los registros coincidentes de archivo1
archivo1_df = archivo1_df.drop(indices_coincidentes)

# Guardar el resultado en un nuevo archivo Excel
with pd.ExcelWriter('Archivo1_Sin_Coincidencias.xlsx', engine='openpyxl') as writer:
    archivo1_df.to_excel(writer, sheet_name='Sheet1', index=False)

# Mostrar el nuevo archivo1 sin las coincidencias
print(archivo1_df)

# Reemplaza 'ruta_del_archivo.txt' con la ruta real de tu archivo
ruta_del_archivo = 'resultados.txt'

# Leer el archivo
with open(ruta_del_archivo, 'r') as file:
    lineas = file.readlines()

# Filtrar las líneas que no contienen 'promedio_general'
lineas_filtradas = [linea for linea in lineas if 'promedio_general' not in linea]

# Escribir las líneas filtradas de nuevo al archivo
with open(ruta_del_archivo, 'w') as file:
    file.writelines(lineas_filtradas)

print("Operación completada. Líneas con 'promedio_general' eliminadas.")

from google.colab import files

# Subir el archivo de entrada
print("Por favor, carga tu archivo de entrada:")
uploaded = files.upload()

# Obtener el nombre del archivo subido
archivo_entrada = list(uploaded.keys())[0]

# Ruta del archivo de salida en Colab
archivo_salida = 'archivo_salida.txt'

# Función para encontrar nombres repetidos y escribirlos en un nuevo archivo
def encontrar_nombres_repetidos(nombres, archivo_salida):
    # Encontrar nombres repetidos
    nombres_repetidos = set([nombre for nombre in nombres if nombres.count(nombre) > 1])

    # Escribir los nombres repetidos en un nuevo archivo
    with open(archivo_salida, 'w') as f:
        for nombre in nombres_repetidos:
            f.write(nombre + '\n')

# Leer los nombres del archivo subido
with open(archivo_entrada, 'r') as f:
    nombres = f.read().splitlines()

# Llamada a la función
encontrar_nombres_repetidos(nombres, archivo_salida)

print(f"Operación completada. Nombres repetidos guardados en '{archivo_salida}'.")

# Cargar archivo manualmente en Colab
from google.colab import files

# Cargar archivo resultados.txt
print("Selecciona el archivo resultados.txt:")
uploaded_resultados = files.upload()

# Guardar contenido del archivo
ruta_resultados = list(uploaded_resultados.keys())[0]

# Leer los contenidos del archivo
with open(ruta_resultados, 'r') as archivo_resultados:
    lineas = archivo_resultados.readlines()

# Adjuntar una coma al final de cada línea
lineas_con_coma = [linea.strip() + ',' for linea in lineas]

# Crear un nuevo archivo con las líneas modificadas
ruta_resultados_con_coma = 'resultados_con_coma.txt'
with open(ruta_resultados_con_coma, 'w') as archivo_resultados_con_coma:
    archivo_resultados_con_coma.writelines(lineas_con_coma)

print("Proceso completado. Los resultados se han guardado en", ruta_resultados_con_coma)

import unittest
import mysql.connector
import time

class TestDatabase(unittest.TestCase):
    def setUp(self):
        # Configura las credenciales de la base de datos
        self.db_connection = mysql.connector.connect(
            host='rds-selecu.cdwgxarbeipl.us-east-1.rds.amazonaws.com',
            user='admin',
            password='2b12QNK9xrv2xoRgUkwOy2T6OK8jbIWLWquojLCC',
            database='prod-selecu'
        )
        self.cursor = self.db_connection.cursor()

    def tearDown(self):
        # Cierra la conexión después de cada prueba
        self.cursor.close()
        self.db_connection.close()

    def test_select_query_performance(self):
        total_start_time = time.time()  # Medir el tiempo total de ejecución

        output = ""  # Almacenar la salida en una variable

        for _ in range(5000):
            start_time = time.time()  # Iniciar el cronómetro para cada ejecución

            # Escribe tu consulta SELECT
            query = """
            SELECT DISTINCT
                u.identification AS Documento,
                u.fullName AS Nombre,
                i.name AS CentroExp,
                g.name AS Grupo,
                g.grade AS Grado,
                qx.question AS Pregunta,
                c.name AS Competencia,
                t.name AS Área,
                CASE
                    WHEN ax.optionId = rx.`option` THEN 'Correcta'
                    ELSE 'Incorrecta'
                END AS Resultado
            FROM
                responses_x rx
                LEFT JOIN options_x ox ON ox.id = rx.option
                LEFT JOIN questions_x qx ON qx.id = rx.questionId
                LEFT JOIN answer_x ax ON ax.optionId = ox.id
                LEFT JOIN competency c ON c.id = qx.competencyId
                LEFT JOIN `prod-selecu`.`user` u ON u.id = rx.userId
                LEFT JOIN realization_x rez ON rez.userId = u.id
                LEFT JOIN topic t ON t.id = qx.topicId
                LEFT JOIN `prod-selecu`.institution i ON u.institutionId = i.id
                LEFT JOIN `prod-selecu`.organization o ON o.id = i.organizationId
                LEFT JOIN `prod-selecu`.group_students gs ON gs.userId = rx.userId
                LEFT JOIN `prod-selecu`.`group` g ON g.id = gs.groupId
            WHERE
                rez.completed = 1
                AND qx.topicId = t.id
                AND t.name = rez.topic
                AND t.name NOT LIKE "%Worldview%"
                AND u.roles = 'Student'
                AND i.organizationId = 1
            ORDER BY
                rx.userId,
                u.fullName,
                t.name
        """

            try:
                # Ejecuta la consulta
                self.cursor.execute(query)
                result = self.cursor.fetchall()

                # Puedes agregar aserciones aquí si es necesario
                # self.assertTrue(len(result) > 0, "La consulta no devolvió ningún resultado")

                end_time = time.time()  # Detener el cronómetro
                elapsed_time = end_time - start_time

                output += f"Iteración {_:>4}: Tiempo de ejecución: {elapsed_time:.4f} segundos\n"
            except Exception as e:
                # Capturar cualquier excepción y mostrarla en la salida
                output += f"Iteración {_:>4}: Error - {str(e)}\n"

        total_end_time = time.time()
        total_elapsed_time = total_end_time - total_start_time
        output += f"\nTiempo total de ejecución para 5000 iteraciones: {total_elapsed_time:.4f} segundos"

        print(output, flush=True)

from google.colab import files

def procesar_nombres(archivo_entrada, archivo_salida):
    # Leer el contenido del archivo
    with open(archivo_entrada, 'r') as file:
        nombres = file.read().splitlines()

    # Procesar cada nombre
    resultados = []
    for nombre in nombres:
        palabras = nombre.split()
        primera_palabra = palabras[0]
        siglas_resto = ''.join([palabra[:2] for palabra in palabras[1:]])

        # Combinar la primera palabra y las siglas del resto
        resultado = primera_palabra + siglas_resto
        resultados.append(resultado.lower())  # Convertir a minúsculas

    # Guardar los resultados en el archivo de salida
    with open(archivo_salida, 'w') as output_file:
        for resultado in resultados:
            output_file.write(resultado + '\n')

    return archivo_salida

# Cargar el archivo desde tu PC
print("Carga el archivo de nombres:")
archivo_entrada = files.upload()

# Obtener el nombre del archivo cargado
nombre_archivo_entrada = list(archivo_entrada.keys())[0]

# Definir el nombre del archivo de salida
nombre_archivo_salida = 'resultados.txt'

# Llama a la función para procesar los nombres y guardar los resultados
archivo_resultados = procesar_nombres(nombre_archivo_entrada, nombre_archivo_salida)

# Imprimir un enlace para descargar el archivo de resultados
print(f"Resultados guardados en: {archivo_resultados}")
files.download(archivo_resultados)

# Lee nombres desde un archivo de texto
with open('dataaa.txt', 'r') as file:
    nombres = [line.strip() for line in file]

# Verificar duplicados
duplicados = set()
unicos = set()

for nombre in nombres:
    if nombre in unicos:
        duplicados.add(nombre)
    else:
        unicos.add(nombre)

if duplicados:
    print("Se encontraron duplicados:")
    for duplicado in duplicados:
        print(duplicado)
else:
    print("No se encontraron duplicados.")

from google.colab import files
import pandas as pd

# Cargar el archivo desde tu PC
uploaded = files.upload()

# Nombre del archivo cargado
archivo_nombre = list(uploaded.keys())[0]

# Cargar el archivo Excel en un DataFrame de pandas
df = pd.read_excel(archivo_nombre)

# Iterar sobre cada fila del DataFrame
for index, row in df.iterrows():
    # Obtener el valor de la columna 'Grupo' en la fila actual
    grupo_actual = row['Grupo']

    # Buscar el valor de 'Codigo' en todas las filas del DataFrame
    resultado = df.loc[df['Codigo'] == grupo_actual, 'ID Codigo'].values

    # Actualizar el valor en la columna 'Resultado'
    df.at[index, 'Resultado'] = resultado[0] if len(resultado) > 0 else None

# Guardar el DataFrame actualizado como un nuevo archivo Excel
resultado_nombre = 'mentores_resultado.xlsx'
df.to_excel(resultado_nombre, index=False)

# Descargar el archivo resultante
files.download(resultado_nombre)

!pip install pandas pymysql

import pandas as pd
import pymysql

# Configuración de la conexión a la base de datos MySQL
user = 'admin'
password = '2b12QNK9xrv2xoRgUkwOy2T6OK8jbIWLWquojLCC'
host = 'rds-selecu.cdwgxarbeipl.us-east-1.rds.amazonaws.com'
database = 'eva-web'
port = 3306  # Por lo general, el puerto de MySQL es 3306

# Crear la conexión a la base de datos
connection = pymysql.connect(host=host, user=user, password=password, database=database, port=port)

# Crear un cursor
cursor = connection.cursor()

# Consulta SQL
sql_query = '''
SELECT
    cu.fullName AS Nombre,
    cu.identification AS Documento,
    cu.institution AS CentroExperiencia,
    cu.grade AS Grado,
    cu.gradeType AS Grupo,
    GROUP_CONCAT(ct.text SEPARATOR ';') AS Contexto,
    q.question AS Pregunta,
    t.name AS Tópico,
    c.name AS Competencia,
    o.option,
    CASE
        WHEN r.option = a.optionID THEN "Correcta"
        ELSE "Incorrecta"
    END as Resultado
FROM
    `eva-web`.responses r
INNER JOIN `prod-selecu`.`comfama-user` cu ON
    r.userId = cu.id
LEFT JOIN `eva-web`.option o ON
    o.id = r.option
LEFT JOIN `eva-web`.question q ON
    q.id = r.questionId
LEFT JOIN `eva-web`.topic t ON
    t.id = q.topicId
LEFT JOIN `eva-web`.competency c ON
    c.id = q.competencyId
LEFT JOIN `eva-web`.context ct ON
    ct.questionId = q.id
LEFT JOIN `eva-web`.answer a ON
    a.questionId = q.id AND r.userId = cu.id
WHERE
    created_at >= '2024-01-19 00:00:00'
    AND created_at < '2024-02-01 00:00:00'
GROUP BY
    cu.fullName,
    cu.identification,
    o.option,
    q.question,
    t.name,
    c.name,
    a.id,
    r.id;
'''

# Ejecutar la consulta
cursor.execute(sql_query)

# Obtener los resultados en un DataFrame
columns = [desc[0] for desc in cursor.description]
df = pd.DataFrame(cursor.fetchall(), columns=columns)

# Cerrar cursor y conexión
cursor.close()
connection.close()

# Guardar el DataFrame en un archivo Excel
df.to_excel('resultados.xlsx', index=False)

def mapear_codigos_a_ids(codigos_a_buscar, mapa):
    # Dividir el mapa en pares de ID y código
    pares_mapa = mapa.split('\n')

    # Crear un diccionario para almacenar la relación de códigos a IDs
    mapa_codigos_ids = {}
    for par in pares_mapa:
        if '=' in par:
            id_, codigo = par.split('=')
            mapa_codigos_ids[codigo] = id_

    # Crear el nuevo mapa
    nuevo_mapa = '\n'.join([f"{mapa_codigos_ids[codigo]}" for codigo in codigos_a_buscar if codigo in mapa_codigos_ids])

    return nuevo_mapa

# Mapa de IDs y códigos
mapa = """
4=12200017
5=12200016
6=12300010
67=12300012
73=12500007
74=12400009
75=13100008
76=13100007
77=13300005
78=13200005
250=12500008
252=12300011
253=12400010
254=13200006
255=13400005
274=12200015
275=12200018
10=12300004
11=12400001
12=12500001
13=13100001
14=13200001
15=13300001
16=13400001
71=12300001
72=12400003
80=12300003
81=12500002
256=12300002
257=12400002
258=12400004
259=13100002
260=13500001
276=12200001
277=12200002
278=12200003
279=12200004
280=12200005
305=13100013
18=12300016
19=12400013
20=12500010
21=13100009
22=13200007
23=13300007
25=13400007
27=13500002
28=13500003
68=13400006
246=12300017
247=12300013
249=12400014
251=12500009
261=13500004
262=13600001
263=13600002
281=12200021
282=12200022
303=12400012
306=12200019
48=12300018
49=12300020
50=12400015
51=12400016
53=12500013
54=13200008
55=13300008
83=13100011
266=12300019
267=12300021
268=12500012
269=13100012
270=13400008
289=13400009
290=12200025
291=12200023
293=12200024
294=13200009
307=12500015
309=13100010
310=13200011
32=12300005
33=12300007
34=12400005
35=12400006
36=12500003
37=13100003
38=13200002
39=13300002
231=13100004
248=12300006
271=12500004
272=13200003
273=13400002
297=12200006
298=12200007
299=12200008
300=12200009
58=12300008
59=12400007
60=12400008
61=12500005
62=12500006
63=13100005
64=13200004
65=13300004
79=12300009
264=13400004
265=13100006
283=12200011
284=12200012
285=12200013
304=13200010
311=13100014
66=11600034
288=11600033
"""

# Códigos a buscar
codigos_a_buscar = [
    "12400003", "12400001", "12500001", "13400007", "12500003", "12300020",
    "12500015", "12500015", "13100010", "13200011", "13200011", "13100008",
    "13100007", "13100005", "13100005", "13100007", "13100007", "13100005",
    "13100007", "13100007", "13100007", "12500006", "13200011", "13200011",
    "13200011", "13100007", "13100007", "13100010", "12300009", "12200019",
    "12500015", "12500015", "13100013", "13100010", "13100010", "13400009",
    "13400009", "13200011", "12500015", "13100007", "13400009", "13100007",
    "12200021", "13400009", "13100007", "12500015", "12500008", "12500015",
    "13100007", "12200021", "12500015", "12500015", "12500015", "13100006",
    "12200005", "13400009", "13400009", "13100007", "13400009", "13400009",
    "13400009", "13400009", "13200011", "12500015", "12500015", "13400009",
    "13100007", "13400009", "13400009", "13100010", "13400009", "12500015",
    "12500015", "13400009", "13400009", "13400009", "13200011", "13100010",
    "13100010", "12500015", "12500015", "12500015", "12500015", "12500015",
    "13100007", "12500015", "13100007", "13400009", "12300021", "12500012",
    "13100007", "13100007", "12300007", "12300006", "12200019", "12200019",
    "12300021", "13100013", "13100013"
]

# Obtener el nuevo mapa
nuevo_mapa = mapear_codigos_a_ids(codigos_a_buscar, mapa)

# Imprimir el nuevo mapa
print(nuevo_mapa)

!pip install pydub

from pydub import AudioSegment
import os

# Instalar pydub

# Montar Google Drive para acceder a los archivos
from google.colab import drive
drive.mount('/content/drive')

# Directorio donde se encuentran los archivos MP3
input_dir = '/content/drive/MyDrive/dataset/'

# Directorio donde se guardarán los archivos WAV convertidos
output_dir = '/content/drive/MyDrive/dataset/conversion'

# Obtener la lista de archivos MP3 en el directorio de entrada
mp3_files = [f for f in os.listdir(input_dir) if f.endswith('.mp3')]

# Convertir cada archivo MP3 a WAV
for mp3_file in mp3_files:
    # Cargar el archivo MP3
    audio = AudioSegment.from_mp3(os.path.join(input_dir, mp3_file))
    # Obtener el nombre del archivo sin la extensión
    filename = os.path.splitext(mp3_file)[0]
    # Guardar el archivo WAV en el directorio de salida
    audio.export(os.path.join(output_dir, f'{filename}.wav'), format='wav')

print("¡La conversión se ha completado!")